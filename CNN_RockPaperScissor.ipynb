{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOqX+mN8OnoGOmeQ68lzsqs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zentochi/CNN_RockPaperScissors/blob/main/CNN_RockPaperScissor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Rock Paper Scissor\n",
        "\n",
        "Bachtiar Danuarta, 31-Dec-2023"
      ],
      "metadata": {
        "id": "t5IzpdAVbCn_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC2FtqZv-CA8",
        "outputId": "6288bc81-9050-43d3-a385-2d4a7d0cd067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-31 12:12:36--  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/391417272/7eb836f2-695b-4a46-9c78-b65867166957?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20231231%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231231T121035Z&X-Amz-Expires=300&X-Amz-Signature=0dd96e8af11d853b92ce32aa1bb8c8c1750ffffc057099b75feb6b56fd65fb5d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=391417272&response-content-disposition=attachment%3B%20filename%3Drockpaperscissors.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-12-31 12:12:36--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/391417272/7eb836f2-695b-4a46-9c78-b65867166957?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20231231%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231231T121035Z&X-Amz-Expires=300&X-Amz-Signature=0dd96e8af11d853b92ce32aa1bb8c8c1750ffffc057099b75feb6b56fd65fb5d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=391417272&response-content-disposition=attachment%3B%20filename%3Drockpaperscissors.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322873683 (308M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/rockpaperscissors.zip’\n",
            "\n",
            "/tmp/rockpapersciss 100%[===================>] 307.92M   293MB/s    in 1.1s    \n",
            "\n",
            "2023-12-31 12:12:38 (293 MB/s) - ‘/tmp/rockpaperscissors.zip’ saved [322873683/322873683]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download datasets\n",
        "!wget https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip -O /tmp/rockpaperscissors.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "pYwL1LsQII7s"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile\n",
        "# Extract datasets\n",
        "local_zip = '/tmp/rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "fHQpf9Gd_gm9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/tmp/rockpaperscissors'\n",
        "train_dir = os.path.join(base_dir,'train')\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "rock_dir = os.path.join(base_dir, 'rock')\n",
        "paper_dir = os.path.join(base_dir, 'paper')\n",
        "scissors_dir = os.path.join(base_dir, 'scissors')\n",
        "\n",
        "# Create train and valisation directory for splitting training and validation\n",
        "os.mkdir(train_dir)\n",
        "os.mkdir(validation_dir)"
      ],
      "metadata": {
        "id": "_9mtiokii1kU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory for train and validation for each datasets\n",
        "train_rock = os.path.join(train_dir, 'rock')\n",
        "train_paper = os.path.join(train_dir, 'paper')\n",
        "train_scissors = os.path.join(train_dir, 'scissors')\n",
        "val_rock = os.path.join(validation_dir, 'rock')\n",
        "val_paper = os.path.join(validation_dir, 'paper')\n",
        "val_scissors = os.path.join(validation_dir, 'scissors')\n",
        "\n",
        "if not os.path.exists(train_rock):\n",
        "  os.mkdir(train_rock)\n",
        "if not os.path.exists(train_paper):\n",
        "  os.mkdir(train_paper)\n",
        "if not os.path.exists(train_scissors):\n",
        "  os.mkdir(train_scissors)\n",
        "\n",
        "if not os.path.exists(val_rock):\n",
        "  os.mkdir(val_rock)\n",
        "if not os.path.exists(val_paper):\n",
        "  os.mkdir(val_paper)\n",
        "if not os.path.exists(val_scissors):\n",
        "  os.mkdir(val_scissors)"
      ],
      "metadata": {
        "id": "Ycg2phRN4nVW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /tmp/rockpaperscissors/train/paper/\n"
      ],
      "metadata": {
        "id": "-k4rWOq8ZR1z"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/tmp/rockpaperscissors/train/rock')) + len(os.listdir('/tmp/rockpaperscissors/train/')) + len(os.listdir('/tmp/rockpaperscissors/paper'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4bCdC_Z4645",
        "outputId": "baa9850d-2d12-4bce-9c69-2a7a39b19e3b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "715"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train and test validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_rock_result, val_rock_result = train_test_split(os.listdir(rock_dir), test_size=0.4) # Validation size is 40% (0.4)\n",
        "train_scissors_result, val_scissors_result = train_test_split(os.listdir(scissors_dir), test_size=0.4)\n",
        "train_paper_result, val_paper_result = train_test_split(os.listdir(paper_dir), test_size=0.4)"
      ],
      "metadata": {
        "id": "n6en5sCFyNIW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "for file in train_rock_result:\n",
        "  shutil.copy(os.path.join(rock_dir, file), os.path.join(train_rock, file))\n",
        "for file in train_paper_result:\n",
        "  shutil.copy(os.path.join(paper_dir, file), os.path.join(train_paper, file))\n",
        "for file in train_scissors_result:\n",
        "  shutil.copy(os.path.join(scissors_dir,file), os.path.join(train_scissors, file))\n",
        "\n",
        "for file in val_rock_result:\n",
        "  shutil.copy(os.path.join(rock_dir, file), os.path.join(val_rock, file))\n",
        "for file in val_paper_result:\n",
        "  shutil.copy(os.path.join(paper_dir, file), os.path.join(val_paper, file))\n",
        "for file in val_scissors_result:\n",
        "  shutil.copy(os.path.join(scissors_dir, file), os.path.join(val_scissors, file))"
      ],
      "metadata": {
        "id": "K1HGc9z_6w_6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentasi gambar\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255)"
      ],
      "metadata": {
        "id": "VSO4PM0an9h8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size= 32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size = (150,150),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOm_SIWuGZ7L",
        "outputId": "c4076076-4266-4906-b553-114913e266ce"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1312 images belonging to 3 classes.\n",
            "Found 876 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(64,(3,3), activation= 'relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(128,(3,3), activation= 'relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(512, activation= 'relu'),\n",
        "  tf.keras.layers.Dense(3, activation= 'softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "llRD338OJAkT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1oRpLtKJMWw",
        "outputId": "1ca737f0-42a0-4122-bbd7-4fe01ebf6b45"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 36992)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 36992)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               18940416  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19035203 (72.61 MB)\n",
            "Trainable params: 19035203 (72.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# latih model dengan model.fit\n",
        "model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=41,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "      epochs=20, # tambahkan epochs jika akurasi model belum optimal\n",
        "      validation_data=validation_generator, # menampilkan akurasi pengujian data validasi\n",
        "      validation_steps=27,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "      verbose=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKfdY9bbJaXG",
        "outputId": "2ab5180a-24da-4f2f-dfbc-ac204d632799"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "41/41 - 20s - loss: 0.8834 - accuracy: 0.6029 - val_loss: 0.4964 - val_accuracy: 0.8090 - 20s/epoch - 476ms/step\n",
            "Epoch 2/20\n",
            "41/41 - 13s - loss: 0.3820 - accuracy: 0.8636 - val_loss: 0.1627 - val_accuracy: 0.9375 - 13s/epoch - 305ms/step\n",
            "Epoch 3/20\n",
            "41/41 - 13s - loss: 0.1835 - accuracy: 0.9383 - val_loss: 0.0836 - val_accuracy: 0.9769 - 13s/epoch - 306ms/step\n",
            "Epoch 4/20\n",
            "41/41 - 13s - loss: 0.1056 - accuracy: 0.9627 - val_loss: 0.0851 - val_accuracy: 0.9722 - 13s/epoch - 313ms/step\n",
            "Epoch 5/20\n",
            "41/41 - 12s - loss: 0.0636 - accuracy: 0.9802 - val_loss: 0.0930 - val_accuracy: 0.9734 - 12s/epoch - 294ms/step\n",
            "Epoch 6/20\n",
            "41/41 - 13s - loss: 0.0626 - accuracy: 0.9787 - val_loss: 0.0764 - val_accuracy: 0.9792 - 13s/epoch - 317ms/step\n",
            "Epoch 7/20\n",
            "41/41 - 13s - loss: 0.0562 - accuracy: 0.9809 - val_loss: 0.0603 - val_accuracy: 0.9826 - 13s/epoch - 305ms/step\n",
            "Epoch 8/20\n",
            "41/41 - 12s - loss: 0.0864 - accuracy: 0.9741 - val_loss: 0.0587 - val_accuracy: 0.9826 - 12s/epoch - 304ms/step\n",
            "Epoch 9/20\n",
            "41/41 - 12s - loss: 0.0858 - accuracy: 0.9733 - val_loss: 0.0635 - val_accuracy: 0.9861 - 12s/epoch - 302ms/step\n",
            "Epoch 10/20\n",
            "41/41 - 12s - loss: 0.0793 - accuracy: 0.9748 - val_loss: 0.1257 - val_accuracy: 0.9676 - 12s/epoch - 300ms/step\n",
            "Epoch 11/20\n",
            "41/41 - 12s - loss: 0.0401 - accuracy: 0.9848 - val_loss: 0.0875 - val_accuracy: 0.9757 - 12s/epoch - 303ms/step\n",
            "Epoch 12/20\n",
            "41/41 - 11s - loss: 0.0275 - accuracy: 0.9909 - val_loss: 0.0845 - val_accuracy: 0.9792 - 11s/epoch - 278ms/step\n",
            "Epoch 13/20\n",
            "41/41 - 12s - loss: 0.0327 - accuracy: 0.9863 - val_loss: 0.0792 - val_accuracy: 0.9803 - 12s/epoch - 297ms/step\n",
            "Epoch 14/20\n",
            "41/41 - 13s - loss: 0.0239 - accuracy: 0.9931 - val_loss: 0.0919 - val_accuracy: 0.9850 - 13s/epoch - 310ms/step\n",
            "Epoch 15/20\n",
            "41/41 - 13s - loss: 0.0305 - accuracy: 0.9909 - val_loss: 0.0601 - val_accuracy: 0.9896 - 13s/epoch - 312ms/step\n",
            "Epoch 16/20\n",
            "41/41 - 12s - loss: 0.1053 - accuracy: 0.9611 - val_loss: 0.2001 - val_accuracy: 0.9433 - 12s/epoch - 302ms/step\n",
            "Epoch 17/20\n",
            "41/41 - 12s - loss: 0.0585 - accuracy: 0.9848 - val_loss: 0.0911 - val_accuracy: 0.9780 - 12s/epoch - 298ms/step\n",
            "Epoch 18/20\n",
            "41/41 - 14s - loss: 0.0328 - accuracy: 0.9886 - val_loss: 0.0811 - val_accuracy: 0.9838 - 14s/epoch - 341ms/step\n",
            "Epoch 19/20\n",
            "41/41 - 12s - loss: 0.0227 - accuracy: 0.9939 - val_loss: 0.1630 - val_accuracy: 0.9711 - 12s/epoch - 304ms/step\n",
            "Epoch 20/20\n",
            "41/41 - 14s - loss: 0.0379 - accuracy: 0.9832 - val_loss: 0.0745 - val_accuracy: 0.9803 - 14s/epoch - 343ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a787ccb2bf0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(fn)\n",
        "  if classes[0,0]!=0:\n",
        "   print('Gunting')\n",
        "  elif classes[0,1]!=0:\n",
        "   print('Batu')\n",
        "  else:\n",
        "    print('kertas')"
      ],
      "metadata": {
        "id": "_IYNcTyBRZHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('saved_model/my_model')"
      ],
      "metadata": {
        "id": "1X84HHpS53re"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model\n",
        "saved_model= './saved_model/my_model/'\n",
        "if not os.path.exists(saved_model):\n",
        "  os.mkdir(saved_model)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model) # path to the SavedModel directory\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "ORyU5r1b324J"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}